import time
import numpy as np
from keras.utils import np_utils
import malware_classification.global_var as GLVAR

epochs=25
batch_size=64


def load_npz_data(file_path):
    f = np.load(file_path)
    x_train, y_train = f['x_train'], f['y_train']
    x_test, y_test = f['x_test'], f['y_test']
    f.close()
    return (x_train, y_train), (x_test, y_test)


def cnn_train(data_file_path):
    (X_Train, y_Train), (X_Test, y_Test) = load_npz_data(data_file_path)

    # Translation of data
    X_Train4D = X_Train.reshape(X_Train.shape[0], GLVAR.pic_pow_size, GLVAR.pic_pow_size, 1).astype('float32')
    X_Test4D = X_Test.reshape(X_Test.shape[0], GLVAR.pic_pow_size, GLVAR.pic_pow_size, 1).astype('float32')

    # Standardize feature data
    X_Train4D_norm = X_Train4D / 255
    X_Test4D_norm = X_Test4D / 255

    # Label Onehot-encoding
    y_TrainOneHot = np_utils.to_categorical(y_Train)
    y_TestOneHot = np_utils.to_categorical(y_Test)

    from keras.models import Sequential
    from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D

    model = Sequential()
    # Create CN layer 1
    model.add(Conv2D(filters=128,
                     kernel_size=(5, 5),
                     padding='same',
                     input_shape=(GLVAR.pic_pow_size, GLVAR.pic_pow_size, 1),
                     activation='relu',
                     name='conv2d_1'))
    # Create Max-Pool 1
    model.add(MaxPool2D(pool_size=(2, 2), name='max_pooling2d_1'))

    # Create CN layer 2
    model.add(Conv2D(filters=64,
                     kernel_size=(5, 5),
                     padding='same',
                     input_shape=(GLVAR.pic_pow_size, GLVAR.pic_pow_size, 1),
                     activation='relu',
                     name='conv2d_2'))

    # Create Max-Pool 2
    model.add(MaxPool2D(pool_size=(2, 2), name='max_pooling2d_2'))

    # Create CN layer 3
    model.add(Conv2D(filters=32,
                     kernel_size=(5, 5),
                     padding='same',
                     input_shape=(GLVAR.pic_pow_size, GLVAR.pic_pow_size, 1),
                     activation='relu',
                     name='conv2d_3'))

    # Create Max-Pool 3
    model.add(MaxPool2D(pool_size=(2, 2), name='max_pooling2d_3'))



    # Add Dropout layer
    model.add(Dropout(0.25, name='dropout_1'))

    model.add(Flatten(name='flatten_1'))

    model.add(Dense(128, activation='relu', name='dense_1'))
    model.add(Dropout(0.5, name='dropout_2'))

    model.add(Dense(GLVAR.NUM_CLASSES, activation='softmax', name='dense_2'))

    model.summary()
    print("")

    # 定義訓練方式
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # 開始訓練
    train_history = model.fit(x=X_Train4D_norm,
                              y=y_TrainOneHot, validation_data=(X_Test4D_norm, y_TestOneHot),
                              epochs=epochs, batch_size=batch_size, verbose=1)

    import matplotlib.pyplot as plt


    def show_train_history(train_history, train, validation):
        plt.plot(train_history.history[train])
        plt.plot(train_history.history[validation])
        title = 'Train History of CNN: epochs-'+str(epochs)+" "+str(time.strftime("%Y-%m-%d %X", time.localtime()))
        plt.title(title)
        plt.ylabel(train)
        plt.xlabel('Epoch')
        plt.legend(['train', 'validation'], loc='upper left')
        plt.show()

    show_train_history(train_history, 'acc', 'val_acc')

    show_train_history(train_history, 'loss', 'val_loss')

    scores = model.evaluate(X_Test4D_norm, y_TestOneHot)
    print()
    print("\t[Info] Accuracy of testing data = {:2.1f}%".format(scores[1] * 100.0))

    print("END.")


def main():

    cnn_train(GLVAR.TRAIN_AND_TEST_DATA)


if __name__ == "__main__":
    main()
