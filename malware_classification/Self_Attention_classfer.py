# %%
from keras.models import model_from_json
from keras.utils import np_utils
from matplotlib import pyplot as plt
import time
from malware_classification.Self_Attention import Self_Attention_Layer

from malware_classification import common_process_data as read_data


num_classes=13
max_features = 983 # 该数要比operation的个数大1
epochs=10

print('Loading data...')

(x_train, y_train), (x_test, y_test) = read_data.load_npz_data("F:/数据集/Kim2016/malware_dataset/malware_dataset/attention_train_test_data_final.npz")
X_train = x_train.reshape(-1,625)  # why / 255?
X_test = x_test.reshape(-1,625)
# 标签转换为独热码
y_train = np_utils.to_categorical(y_train, num_classes=num_classes)
y_test = np_utils.to_categorical(y_test, num_classes=num_classes)
print(len(x_train), 'train sequences')
print(len(x_test), 'test sequences')

# %%数据归一化处理

maxlen = 625

print('x_train shape:', x_train.shape)

print('x_test shape:', x_test.shape)



# %%

batch_size = 32
from keras.models import Model
from keras.optimizers import SGD, Adam
from keras.layers import *
# from Attention_keras import Attention, Position_Embedding

S_inputs = Input(shape=(625,), dtype='int32')

embeddings = Embedding(max_features, 256)(S_inputs)

O_seq = Self_Attention_Layer(256)(embeddings)

O_seq = GlobalAveragePooling1D()(O_seq)

O_seq = Dropout(0.5)(O_seq)

outputs = Dense(13, activation='softmax')(O_seq)

model = Model(inputs=S_inputs, outputs=outputs)

print(model.summary())
# try using different optimizers and different optimizer configs
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# %%
print('Train...')

h = model.fit(x_train, y_train,

              batch_size=batch_size,

              epochs=epochs,

              validation_data=(x_test, y_test))

plt.plot(h.history["loss"], label="train_loss")
plt.plot(h.history["val_loss"], label="val_loss")
plt.plot(h.history["acc"], label="train_acc")
plt.plot(h.history["val_acc"], label="val_acc")
plt.legend()
plt.show()

print('Testing--------------')
loss, accuracy = model.evaluate(X_test, y_test)

print('test loss:', loss)
print('test accuracy:', accuracy)


print("-----------------------DY Add------------------------")
import matplotlib.pyplot as plt


def show_train_history(train_history, train, validation):
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[validation])
    title = 'Train History of Self-Attention: epochs-' + str(epochs) + " " + str(time.strftime("%Y-%m-%d %X", time.localtime()))
    plt.title(title)
    plt.ylabel(train)
    plt.xlabel('Epoch')
    plt.legend(['train', 'validation'], loc='upper left')
    plt.show()


show_train_history(h, 'acc', 'val_acc')

show_train_history(h, 'loss', 'val_loss')

scores = model.evaluate(X_test, y_test)
print()
print("\t[Info] Accuracy of testing data = {:2.1f}%".format(scores[1] * 100.0))


model.save("F:/数据集/Kim2016/malware_dataset/malware_dataset/self_attention_model_final.h5")


